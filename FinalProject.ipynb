{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4fcbf23-e8e9-4677-b50a-95ae756b7dd9",
   "metadata": {},
   "source": [
    "# Assessing accuracy of TrOCR model using IAM Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd70492-a0ba-4090-86ca-9a4c69d2f56b",
   "metadata": {},
   "source": [
    "In this project, I sought to use a recent optical character recognition model from this paper: https://arxiv.org/pdf/2109.10282\n",
    "\n",
    "I begin by playing with the TrOCR model with some handwritten text of my own. I determine the effectiveness of the model both without noise and in the presence of Gaussian and Poisson noise.\n",
    "\n",
    "Next, I input text from the famous IAM Handwritten Database. I assess the accuracy of the model in identifying written words both before and after the addition of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752206c9-d752-4abb-94eb-f68f00633248",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e27bd20-28c1-4e5d-8e8d-6d55729756be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image, ImageDraw\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868a0b9-9885-4989-937e-caff76bfcba7",
   "metadata": {},
   "source": [
    "## Loading Pretrained Model and Applying to First Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52750e49-75ec-4969-8dc1-497663ae38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trial image from the IAM database\n",
    "# url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'\n",
    "# image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76bf37ca-39f6-45ad-8f51-1e42fe6b9015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.47.0\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.47.0\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Access Pretrained TrOCR Model\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b9bc6f2-8b7f-463f-8b1f-538befc68fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a51c7e-b934-4a34-99e7-11c327f84b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc3a3669-0ccb-48fc-b02e-740d5675f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indus the\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0780cac-320b-4518-a149-b7845efc8594",
   "metadata": {},
   "source": [
    "As we can see, the text (industrie) is a little difficult to read, but the model does a fairly good job reading the text. Next, we provide the model with more nicely written text. Then, we will determine whether the model can read the text in the presence of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0061c3e8-06e9-4df9-8ebc-939732c79366",
   "metadata": {},
   "source": [
    "## Applying Model to Image Applied for Project Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9416eee6-67ed-4ac2-a669-38aee6304541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in Personal Image \n",
    "personalImage = Image.open(\"/Users/chandle/Desktop/STATS507/Data_Project/FinalProject_chandle/STATS507_FinalProject/ProjectProposal/brothersGonnaWorkIt.jpg\").convert(\"RGB\")\n",
    "personalImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20666f99-6d3b-4e2c-905c-53cbd8426269",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = processor(images=personalImage, return_tensors=\"pt\").pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5738d343-7b78-4695-ab58-ce3c43dc921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brothers gonna work it out\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f40fa6-220e-45c5-aa64-387c7b63a5d0",
   "metadata": {},
   "source": [
    "Running TrOCR works exactly as it should! Very exciting! Indeed, this system is already working better than the model that was applied in the project proposal (the previous model, paddleOCR, identified \"g\" as a \"q\"). This is a great start, but let's see how this models performs in the presence of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4dde76-3c22-4b4e-829f-b46e82ffa817",
   "metadata": {},
   "source": [
    "## Helper Functions - Altering Images, Adding Noise, Checking Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81786d1-de55-47c7-ac27-0ac71ee51aa1",
   "metadata": {},
   "source": [
    "Below, we write out the functions for adding noise to our text. This was done in the project proposal, but we clean the code here for ease of application for others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c953cb-7fca-4f81-888e-a11aab7c05a9",
   "metadata": {},
   "source": [
    "### Changing Image to Grayscale (if necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088d262-955b-4f6e-b33d-e23dce2aafe9",
   "metadata": {},
   "source": [
    "The following code changes the text image to grayscale (all of the text in the IMA dataset is already grayscale, but if the user wants to apply TrOCR, this step may be necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cb8a5b6-9602-4d2e-a6e1-8e7ff605c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_grayscale(image):\n",
    "    image = image.convert(\"L\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed8888-d465-4cf6-b735-054ec2f5f31e",
   "metadata": {},
   "source": [
    "### Adding Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3de76b85-4b61-4393-b418-04e923f5dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_noise(image, variance):\n",
    "  mean = 0\n",
    "  var = variance\n",
    "  sigma = var**0.5\n",
    "  gauss = np.random.normal(mean, sigma, image.shape)\n",
    "  gauss = np.reshape(gauss, newshape = (image.shape[0], image.shape[1], image.shape[2]), order = \"F\")\n",
    "  noisy = image + gauss\n",
    "  return noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52969bcb-3a36-4620-ba8a-79eed8d6ec47",
   "metadata": {},
   "source": [
    "## Applying Model to Noisy Image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dae80d-45d2-4bf4-83f8-f172f2c439b4",
   "metadata": {},
   "source": [
    "First, we add Gaussian noise using the function defined above; we add the same Gaussian noise to each color channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "911d2aac-179c-40c2-9c7b-4d208af311db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determining if grayscale conversion affects model performance\n",
    "personalImage = Image.open(\"/Users/chandle/Desktop/STATS507/Data_Project/FinalProject_chandle/STATS507_FinalProject/ProjectProposal/brothersGonnaWorkIt.jpg\").convert(\"RGB\")\n",
    "personalImage_GaussNoise = gauss_noise(np.array(personalImage), 100000)\n",
    "cv2.imwrite('personalImage_GaussNoise.jpg', personalImage_GaussNoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560c0323-957a-40d0-b959-212d42179ce6",
   "metadata": {},
   "source": [
    "Next, we reopen the noisy image with the library Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bce38a4a-9472-439c-ba89-591d0ddecfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "personalImage_GaussNoise = Image.open(\"/Users/chandle/Desktop/STATS507/Data_Project/FinalProject_chandle/STATS507_FinalProject/personalImage_GaussNoise.jpg\")\n",
    "personalImage_GaussNoise.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fc680-0042-4f9c-88c4-00dd845fdfc1",
   "metadata": {},
   "source": [
    "Finally, we can assess model performance on this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d564de83-aa0a-47be-89b9-8b95cbe0073c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixel_values = processor(images=personalImage_GaussNoise, return_tensors=\"pt\").pixel_values\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a62b330d-9583-4872-8d79-ff67e9b4cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brothers gave back it out\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba427372-4f4d-45dc-a10a-37dce093c5a9",
   "metadata": {},
   "source": [
    "As we can see, if the noise is sufficiently high, the model fails to perform. That said, it is still performing *much* better than the model that was tested for the project proposal. Next, we begin reading in text from the IMA dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eacad2-bb67-43f4-b0d1-66c5a4667900",
   "metadata": {},
   "source": [
    "## Checking to see if threshold% of Array Elements are Equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd27b4ba-faba-4f52-80c1-61892c7d12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks to see if threshold% of the elements in the output_array are in the correct_array\n",
    "def check_arrays(correct_array, output_array, threshold):\n",
    "    correct = 0\n",
    "    for element in output_array:\n",
    "        if element in correct_array:\n",
    "            correct += 1\n",
    "    if (correct / len(correct_array)) >= threshold:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0e2eb-c5b7-4aae-8ee5-dcdb5d7185f4",
   "metadata": {},
   "source": [
    "## Reading in Text from the IMA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a1514a-186d-446f-82a8-4d338e4def26",
   "metadata": {},
   "source": [
    "### IMA Image without Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fd64c28-516e-4e06-b7ce-ce509b63669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstIMAImage = Image.open(\"/Users/chandle/Desktop/STATS507/Data_Project/FinalProject_chandle/STATS507_FinalProject/words/b02/b02-013/b02-013-08-02.png\").convert(\"RGB\")\n",
    "firstIMAImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91a9fa47-e019-4ae7-8880-b2e2ffacd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = processor(images=firstIMAImage, return_tensors=\"pt\").pixel_values\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3ab2572-8434-4ea8-9e0a-7f8b8de0688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beedd67c-2626-4a85-bc62-bfccf3635680",
   "metadata": {},
   "source": [
    "The model correctly identified the text. Next, we determine how the model performs on this image in the presence of noise. After that, we can begin to apply the model to a larger dataset to assess the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68be9f-b0e0-4c1d-86b7-6611310bcda3",
   "metadata": {},
   "source": [
    "### IMA Image with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63c02bad-ae4f-4fbc-83cc-7031d0ae3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstIMAImage_noise = Image.open(\"/Users/chandle/Desktop/STATS507/Data_Project/FinalProject_chandle/STATS507_FinalProject/words/b02/b02-013/b02-013-08-02.png\").convert(\"RGB\")\n",
    "firstIMAImage_noise.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc5678f5-8876-4fe7-9623-758a07d68943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstIMAImage_noise = gauss_noise(np.array(firstIMAImage_noise), 10000)\n",
    "cv2.imwrite('firstIMAImage_noise.jpg', firstIMAImage_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15b4e849-a50c-49d2-a3cb-40f50bab2ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstIMAImage_noise = Image.open(\"/Users/chandle/Desktop/STATS507/Data_Project/FinalProject_chandle/STATS507_FinalProject/firstIMAImage_noise.jpg\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c1b43cc-edfe-4f5f-925a-a37b4a4615b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = processor(images=firstIMAImage_noise, return_tensors=\"pt\").pixel_values\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "503a6468-6bee-4ee2-ae84-6725d562d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of the team's life\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8630bf-0ec2-4728-823e-5f5f3ac36b84",
   "metadata": {},
   "source": [
    "The model *completely* failed with this level of noise. We now proceed to the thrust of this project: we will determine the model performance under different levels of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfdf7d6-2b93-4aff-9b22-6c177295a547",
   "metadata": {},
   "source": [
    "## Reading in Directory with Correct Sentences and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb37ab4d-dbf0-4ee3-a473-79ecbd9aaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_directory = \"/Users/chandle/Desktop/STATS507/Data_Project/FinalProject_chandle/STATS507_FinalProject/sentences_flatten\"\n",
    "corrupted_directory = \"/Users/chandle/Desktop/STATS507/Data_Project/FinalProject_chandle/STATS507_FinalProject/sentences_corrupted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d4c0c00-e6dd-4c3c-911f-32e8ec24e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function selects n files randomly from a given path\n",
    "def select_random_file(directory):\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    if not files:\n",
    "        return None\n",
    "    return np.random.choice(files, 1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38c6687d-d67b-4e31-b629-60a3af51abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following stores the random selection of files\n",
    "my_file_list = select_random_file(flatten_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163aced-e1d4-425b-88ef-87c1d5fc93f1",
   "metadata": {},
   "source": [
    "## Applying Model to IAM Handwritten Dataset, No noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64f353ad-88ac-4a5a-a16b-0ee2fe7cbdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following identifies the words in each entry of my_file_list based on ascii/sentences.txt\n",
    "sentence_oracle_dir = \"/Users/chandle/Desktop/STATS507/Data_Project/FinalProject_chandle/STATS507_FinalProject/ascii/sentences_manipulate.txt\"\n",
    "file_and_correct_sentence = {}\n",
    "with open(sentence_oracle_dir, 'r') as file:\n",
    "    for line in file:\n",
    "        file_name = line.split(\" \")[0]\n",
    "        correct_sentence = (\" \".join(line.split(\" \")[-1].split(\"|\"))).replace(\"\\n\", \"\")\n",
    "        file_and_correct_sentence[file_name] = correct_sentence.split(\" \")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d515328f-4a9c-47f0-a5de-933dbbb1492c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'d06-020-s03-03_corrupt_var=6400 .jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m my_file_list_final \u001b[38;5;241m=\u001b[39m my_file_list[i]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m check_arrays(file_and_correct_sentence[my_file_list_final], generated_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m0.7\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'd06-020-s03-03_corrupt_var=6400 .jpg'"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(my_file_list)):\n",
    "    \n",
    "    path_to_pic = flatten_directory + '/' + my_file_list[i]\n",
    "    readingImage = Image.open(path_to_pic).convert(\"RGB\")\n",
    "    pixel_values = processor(images=readingImage, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    my_file_list_final = my_file_list[i].replace(\".png\", \"\")\n",
    "    correct += check_arrays(file_and_correct_sentence[my_file_list_final], generated_text.split(\" \"), 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f10d169b-c7ef-4fb0-8afd-f356ccfe8b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897\n"
     ]
    }
   ],
   "source": [
    "print(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5537cb-1886-4d2c-bcf2-48e4d3f4ffed",
   "metadata": {},
   "source": [
    "## Applying Model in the Presence of Gaussian Noise, $\\text{Noise} \\sim \\mathcal{N}(0, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bde63-92a7-459e-996c-d1718a587a0e",
   "metadata": {},
   "source": [
    "Now that we have analyzed the proportion of sentences the model predicts correctly, we now proceed to determine model performance in the presence of noise. This is not fundamentally different than the previous section; we carry out precisely the same data pipeline, but now include code to evaluate model performance when noise is added. We steadily increase noise and record the deterioration in model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfa4e62-a9c5-4e8e-84f5-c8e718341700",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m var \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6400\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(my_file_list)):\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Reads in original image\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     path_to_pic \u001b[38;5;241m=\u001b[39m flatten_directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m my_file_list[i]\n\u001b[1;32m      7\u001b[0m     readingImage \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(path_to_pic)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_file_list' is not defined"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "var = 6400\n",
    "for i in range(len(my_file_list)):\n",
    "\n",
    "    # Reads in original image\n",
    "    path_to_pic = flatten_directory + '/' + my_file_list[i]\n",
    "    readingImage = Image.open(path_to_pic).convert(\"RGB\")\n",
    "\n",
    "    # Writes Corrupted Image\n",
    "    corrupt_path = corrupted_directory + '/' my_file_list[i] '/' + f\"_corrupt_var={var}\" + \".jpg\"\n",
    "    temp_corrupt = gauss_noise(np.array(readingImage), var)\n",
    "    cv2.imwrite(corrupt_path, temp_corrupt)\n",
    "    \n",
    "    # Read in Corrupted Image\n",
    "    corruptedImage = Image.open(corrupt_path).convert(\"RGB\")\n",
    "    \n",
    "    # Process Corrupted Image\n",
    "    pixel_values = processor(images=corruptedImage, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    my_file_list_final = my_file_list[i].replace(\".png\", \"\")\n",
    "    correct += check_arrays(file_and_correct_sentence[my_file_list_final], generated_text.split(\" \"), 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148e581-6c44-4e23-a367-b505c3b22577",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
